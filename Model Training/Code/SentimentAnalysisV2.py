# Version 2 of Sentiment Analysis approach
# Planned process:
    # Split dataset into 70/30 
    # Vader used to classify sentiment polarity + intensity  
    # TF-IDF then captures word importance 
    # Run these for every headline in 70% 
    # Together they are the vectors for training model 
    # Train logistic regression model on these features 
    # Test model on remaining 20% test data  
    # Measure model performance using accuracy, and f1 score 

# Dataset is currently 1500 headlines generated by ChatGPT
# 500 pos, 500 neg, 500 neu

# Used for reading in the data
import pandas as pd
# Scikit learn used for ML
from sklearn.model_selection import train_test_split
# VADER classification
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
# TD-IDF Vectorising
from sklearn.feature_extraction.text import TfidfVectorizer
# Logistic Regression
from sklearn.linear_model import LogisticRegression
# Label encoder used for encoding pos,neg, neut in training
from sklearn.preprocessing import LabelEncoder
# For model evaluation
from sklearn.metrics import accuracy_score, f1_score, classification_report
#  For saving the model
import pickle

def shuffle_and_split_dataset(file_path):
    # Load dataset
    df = pd.read_excel(file_path, sheet_name="Dataset")
    
    # Display initial class distribution to ensure 500/500/500
    print("Initial Class Distribution:\n", df["Labelled Rating"].value_counts())

    # Shuffle dataset
    # Random state is 42, thank Hitchhikers guide to the galaxy 
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)

    # Stratify command ensures that Labelled Rating is equally split for each section which hopefully reduces overfitting
    # Split into 80/20 split
    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df["Labelled Rating"])

    # Save splits into separate Excel files
    train_df.to_excel("Train_DatasetImprovedFinal.xlsx", index=False)
    #val_df.to_excel("Validation_Dataset.xlsx", index=False)
    test_df.to_excel("Test_DatasetImprovedFinal.xlsx", index=False)

    # Display split sizes
    print(f"Training set: {len(train_df)} headlines")
    #print(f"Validation set: {len(val_df)} headlines")
    print(f"Test set: {len(test_df)} headlines")

def apply_vader(df, text_column="Statement"):
    # Initialise VADER
    analyser = SentimentIntensityAnalyzer()

    # Function to get VADER scores
    def get_vader_scores(text):
        scores = analyser.polarity_scores(text)
        return pd.Series([scores['pos'], scores['neg'], scores['neu'], scores['compound']])

    # Apply VADER to the dataset
    df[['pos', 'neg', 'neu', 'compound']] = df[text_column].apply(get_vader_scores)
    
    return df

def apply_tfidf(df, text_column="Statement"):
    # Initialise TF-IDF vectoriser
    vectoriser = TfidfVectorizer(ngram_range=(1,1), max_features= 750) 

    # Fit and transform the text data
    tfidf_matrix = vectoriser.fit_transform(df[text_column])

    # Convert TF-IDF matrix to DataFrame
    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectoriser.get_feature_names_out())

    return tfidf_df, vectoriser

def train_model(train_file):
    # Load the training dataset
    df = pd.read_excel(train_file)

    # Extract features (VADER + TF-IDF) and labels
    # X features are VADER and TF-IDF data points
    X_train = df.drop(columns=["Labelled Rating"]) 
    # Y features are the sentiment labels 
    y_train = df["Labelled Rating"]

    # Encode sentiment labels as numerical values
    label_encoder = LabelEncoder()
    # Converts labels (positive, negative, neutral) into numbers
    y_train = label_encoder.fit_transform(y_train)  

    # Logistic regression model, currently set to 1000 iterations
    model = LogisticRegression(max_iter=100)

    # Train the model
    model.fit(X_train, y_train) 

    print("TF-IDF training feature names:", vectoriser.get_feature_names_out())

    feature_order = vectoriser.get_feature_names_out()
    
    # Save model, vectoriser, label encoder and feature order
    with open("feature_order.pkl", "wb") as file:
        pickle.dump(feature_order, file)

    with open("final_model_improved.pkl", "wb") as model_file:
        pickle.dump(model, model_file)

    with open("tfidf_vectoriser_improved.pkl", "wb") as vectorizer_file:
        pickle.dump(vectoriser, vectorizer_file)

    with open("label_encoder_improved.pkl", "wb") as encoder_file:
        pickle.dump(label_encoder, encoder_file)

    print("Final model trained and saved successfully.")
    return model, vectoriser, label_encoder

def test_model(model, vectoriser, label_encoder, test_file="Test_DatasetImprovedFinal.xlsx"):
    # Load test dataset
    test_df = pd.read_excel(test_file)

    # Extract VADER sentiment scores
    test_df = apply_vader(test_df)

    # Extract TF-IDF features using the same vectoriser from training
    tfidf_matrix = vectoriser.transform(test_df["Statement"])
    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectoriser.get_feature_names_out())

    # Combine VADER and TF-IDF features
    X_test = pd.concat([test_df[['pos', 'neg', 'neu', 'compound']], tfidf_df], axis=1)

    # Convert labels to numerical values
    y_true = label_encoder.transform(test_df["Labelled Rating"])

    # Predict sentiment
    y_pred = model.predict(X_test)

    return y_true, y_pred

def evaluate_model(y_true, y_pred, label_encoder):
    # Calculate accuracy
    accuracy = accuracy_score(y_true, y_pred)
    print(f"Model Accuracy: {accuracy:.2f}")

    # Calculate F1 Score
    f1 = f1_score(y_true, y_pred, average="weighted")
    print(f"F1 Score: {f1:.2f}")

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))


# MAIN FUNCTIONS TO RUN

if __name__ == "__main__":

    # 1) Shuffle the whole dataset
    shuffle_and_split_dataset("DatasetTesting.xlsx")
    print("Shuffled dataset")

    # 2) Load training dataset
    train_df = pd.read_excel("Train_DatasetImprovedFinal.xlsx")
    print("Dataset loaded")

    # # 3) Apply VADER
    train_df = apply_vader(train_df)
    print("VADER applied successfully")

    # # 4) Apply TF-IDF
    tfidf_df, vectoriser = apply_tfidf(train_df)
    print("TF-IDF applied successfully")

    # # 5) Combine VADER and TF-IDF features 
    final_train_df = pd.concat([train_df[['Labelled Rating','pos', 'neg', 'neu', 'compound']], tfidf_df], axis=1)
    print("Features combined for final training excel")

    # # 6) Save processed dataset into Excel
    final_train_df.to_excel("Train_Dataset_FinalImproved.xlsx", index=False)
    print("VADER and TF-IDF processing completed and saved successfully")

    # 7) Train model using preprocessed dataset
    model, vectoriser, label_encoder = train_model("Train_Dataset_FinalImproved.xlsx")
    
    # 8) Test model on 30% test set (450 heasdlines)
    y_true, y_pred = test_model(model, vectoriser, label_encoder)
    print("Testing done and dusted")

    # 9) Evaluate the model on Accuracy and F1 score
    evaluate_model(y_true, y_pred, label_encoder)
